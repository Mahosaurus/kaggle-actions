{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from rwanda.src.utils import get_repo_root\n",
    "from rwanda.src.impute import impute_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training data\n",
    "train = pd.read_csv(f'{get_repo_root()}/data/train.csv')\n",
    "# Read test data\n",
    "test = pd.read_csv(f'{get_repo_root()}/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From data frame train, extract from ID_LAT_LON_YEAR_WEEK column ID_LAT_LON as a new column\n",
    "train['ID_LAT_LON'] = [\"_\".join(x.split('_')[0:3]) for x in train['ID_LAT_LON_YEAR_WEEK']]\n",
    "test['ID_LAT_LON'] = [\"_\".join(x.split('_')[0:3]) for x in test['ID_LAT_LON_YEAR_WEEK']]\n",
    "# From data frame train, extract from ID_LAT_LON_YEAR_WEEK column YEAR_WEEK as a new column\n",
    "train[\"year_week\"] = [\"_\".join(x.split('_')[3:5]) for x in train['ID_LAT_LON_YEAR_WEEK']]\n",
    "test[\"year_week\"] = [\"_\".join(x.split('_')[3:5]) for x in test['ID_LAT_LON_YEAR_WEEK']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = impute_data(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "\n",
    "# Concat train and test\n",
    "concat_df = pd.concat([train, test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sulphur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlations between all variables starting with Sulphur in train\n",
    "#sns.heatmap(concat_df.filter(regex='^Sulphur').corr(), cmap='coolwarm', annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a PCA on variables X\n",
    "X = '^Sulphur'\n",
    "comps = 6\n",
    "\n",
    "pca = PCA(n_components=comps)\n",
    "# Standardize concat_df.filter(regex='^Sulphur')) columns\n",
    "tmp = StandardScaler().fit_transform(concat_df.filter(regex=X))\n",
    "# Fit the PCA model\n",
    "pca.fit(tmp)\n",
    "# Plot the explained variance ratio\n",
    "print(pca.explained_variance_ratio_)\n",
    "# Replace the original variables with the principal components\n",
    "components = pca.transform(tmp)\n",
    "## Drop the original variables\n",
    "concat_df = concat_df.drop(concat_df.filter(regex=X).columns, axis=1)\n",
    "## Add the principal components to the dataframe\n",
    "for i in range(comps):\n",
    "    concat_df[f'{X[1:]}_{i+1}'] = components[:, i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nitrogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlations between all variables starting with Nitrogen in train\n",
    "# sns.heatmap(concat_df.filter(regex='^Nitrogen').corr(), cmap='coolwarm', annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a PCA on variables X\n",
    "X = '^Nitrogen'\n",
    "comps = 4\n",
    "\n",
    "pca = PCA(n_components=comps)\n",
    "# Standardize concat_df.filter(regex='^Sulphur')) columns\n",
    "tmp = StandardScaler().fit_transform(concat_df.filter(regex=X))\n",
    "# Fit the PCA model\n",
    "pca.fit(tmp)\n",
    "# Plot the explained variance ratio\n",
    "print(pca.explained_variance_ratio_)\n",
    "# Replace the original variables with the principal components\n",
    "components = pca.transform(tmp)\n",
    "## Drop the original variables\n",
    "concat_df = concat_df.drop(concat_df.filter(regex=X).columns, axis=1)\n",
    "## Add the principal components to the dataframe\n",
    "for i in range(comps):\n",
    "    concat_df[f'{X[1:]}_{i+1}'] = components[:, i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formaldehyde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlations between all variables starting with Nitrogen in train\n",
    "sns.heatmap(concat_df.filter(regex='^Formaldehyde').corr(), cmap='coolwarm', annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = '^Form'\n",
    "comps = 5\n",
    "\n",
    "pca = PCA(n_components=comps)\n",
    "# Standardize concat_df.filter(regex='^Sulphur')) columns\n",
    "tmp = StandardScaler().fit_transform(concat_df.filter(regex=X))\n",
    "# Fit the PCA model\n",
    "pca.fit(tmp)\n",
    "# Plot the explained variance ratio\n",
    "print(pca.explained_variance_ratio_)\n",
    "# Replace the original variables with the principal components\n",
    "components = pca.transform(tmp)\n",
    "## Drop the original variables\n",
    "concat_df = concat_df.drop(concat_df.filter(regex=X).columns, axis=1)\n",
    "## Add the principal components to the dataframe\n",
    "for i in range(comps):\n",
    "    concat_df[f'{X[1:]}_{i+1}'] = components[:, i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CarbonMonoxide_sensor_azimuth_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlations between all variables starting with Nitrogen in train\n",
    "sns.heatmap(concat_df.filter(regex='^Carbon').corr(), cmap='coolwarm', annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = '^Carbon'\n",
    "comps = 4\n",
    "\n",
    "pca = PCA(n_components=comps)\n",
    "# Standardize concat_df.filter(regex='^Sulphur')) columns\n",
    "tmp = StandardScaler().fit_transform(concat_df.filter(regex=X))\n",
    "# Fit the PCA model\n",
    "pca.fit(tmp)\n",
    "# Plot the explained variance ratio\n",
    "print(pca.explained_variance_ratio_)\n",
    "# Replace the original variables with the principal components\n",
    "components = pca.transform(tmp)\n",
    "## Drop the original variables\n",
    "concat_df = concat_df.drop(concat_df.filter(regex=X).columns, axis=1)\n",
    "## Add the principal components to the dataframe\n",
    "for i in range(comps):\n",
    "    concat_df[f'{X[1:]}_{i+1}'] = components[:, i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UvAerosolIndex_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(concat_df.filter(regex='^Uv').corr(), cmap='coolwarm', annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = '^Uv'\n",
    "comps = 3\n",
    "\n",
    "pca = PCA(n_components=comps)\n",
    "# Standardize concat_df.filter(regex='^Sulphur')) columns\n",
    "tmp = StandardScaler().fit_transform(concat_df.filter(regex=X))\n",
    "# Fit the PCA model\n",
    "pca.fit(tmp)\n",
    "# Plot the explained variance ratio\n",
    "print(pca.explained_variance_ratio_)\n",
    "# Replace the original variables with the principal components\n",
    "components = pca.transform(tmp)\n",
    "## Drop the original variables\n",
    "concat_df = concat_df.drop(concat_df.filter(regex=X).columns, axis=1)\n",
    "## Add the principal components to the dataframe\n",
    "for i in range(comps):\n",
    "    concat_df[f'{X[1:]}_{i+1}'] = components[:, i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ozone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(concat_df.filter(regex='^Ozone').corr(), cmap='coolwarm', annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = '^Ozone'\n",
    "comps = 4\n",
    "\n",
    "pca = PCA(n_components=comps)\n",
    "# Standardize concat_df.filter(regex='^Sulphur')) columns\n",
    "tmp = StandardScaler().fit_transform(concat_df.filter(regex=X))\n",
    "# Fit the PCA model\n",
    "pca.fit(tmp)\n",
    "# Plot the explained variance ratio\n",
    "print(pca.explained_variance_ratio_)\n",
    "# Replace the original variables with the principal components\n",
    "components = pca.transform(tmp)\n",
    "## Drop the original variables\n",
    "concat_df = concat_df.drop(concat_df.filter(regex=X).columns, axis=1)\n",
    "## Add the principal components to the dataframe\n",
    "for i in range(comps):\n",
    "    concat_df[f'{X[1:]}_{i+1}'] = components[:, i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(concat_df.filter(regex='^Cloud').corr(), cmap='coolwarm', annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = '^Cloud'\n",
    "comps = 3\n",
    "\n",
    "pca = PCA(n_components=comps)\n",
    "# Standardize concat_df.filter(regex='^Sulphur')) columns\n",
    "tmp = StandardScaler().fit_transform(concat_df.filter(regex=X))\n",
    "# Fit the PCA model\n",
    "pca.fit(tmp)\n",
    "# Plot the explained variance ratio\n",
    "print(pca.explained_variance_ratio_)\n",
    "# Replace the original variables with the principal components\n",
    "components = pca.transform(tmp)\n",
    "## Drop the original variables\n",
    "concat_df = concat_df.drop(concat_df.filter(regex=X).columns, axis=1)\n",
    "## Add the principal components to the dataframe\n",
    "for i in range(comps):\n",
    "    concat_df[f'{X[1:]}_{i+1}'] = components[:, i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwanda-qMl64OKB-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
