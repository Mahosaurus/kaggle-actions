{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from rwanda.src.utils import get_repo_root\n",
    "from rwanda.src.impute import impute_data\n",
    "from rwanda.src.reduce import reduce_dimenions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training data\n",
    "train = pd.read_csv(f'{get_repo_root()}/data/train.csv')\n",
    "# Read test data\n",
    "test = pd.read_csv(f'{get_repo_root()}/data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make ID and datevar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From data frame train, extract from ID_LAT_LON_YEAR_WEEK column ID_LAT_LON as a new column\n",
    "train['ID_LAT_LON'] = [\"_\".join(x.split('_')[0:3]) for x in train['ID_LAT_LON_YEAR_WEEK']]\n",
    "test['ID_LAT_LON'] = [\"_\".join(x.split('_')[0:3]) for x in test['ID_LAT_LON_YEAR_WEEK']]\n",
    "# From data frame train, extract from ID_LAT_LON_YEAR_WEEK column YEAR_WEEK as a new column\n",
    "train[\"year_week\"] = [\"_\".join(x.split('_')[3:5]) for x in train['ID_LAT_LON_YEAR_WEEK']]\n",
    "test[\"year_week\"] = [\"_\".join(x.split('_')[3:5]) for x in test['ID_LAT_LON_YEAR_WEEK']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dim Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Approach:\n",
    "- this just continues to roll out the weighted mean of the last 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train[['ID_LAT_LON', 'year_week', 'emission']]\n",
    "# Sort train by ID_LAT_LON and year_week\n",
    "df = df.sort_values(by=['ID_LAT_LON', 'year_week'])\n",
    "\n",
    "# Group df by ID_LAT_LON and get the last 7 rows\n",
    "df = df.groupby(['ID_LAT_LON']).tail(7)\n",
    "# Create a new column with the weighted mean of the last 7 rows\n",
    "df['emission_7'] = df.groupby(['ID_LAT_LON'])['emission'].transform(lambda x: x.rolling(7, 1).mean())\n",
    "# Take the last value of the weighted mean\n",
    "df = df.groupby(['ID_LAT_LON']).tail(1)\n",
    "\n",
    "# Rename emission_7 to emission\n",
    "df.drop([\"emission\"], axis=1, inplace=True)\n",
    "df = df.rename(columns={'emission_7': 'emission'})\n",
    "\n",
    "# Merge test and df 1:m on ID_LAT_LON\n",
    "test = test[['ID_LAT_LON', 'ID_LAT_LON_YEAR_WEEK']]\n",
    "submission = pd.merge(test, df, on='ID_LAT_LON', how='left')\n",
    "submission = submission[['ID_LAT_LON_YEAR_WEEK', 'emission']]\n",
    "\n",
    "# Make submission\n",
    "submission.loc[submission[\"emission\"] < 0, \"emission\"] = 0\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale year approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwanda-qMl64OKB-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
